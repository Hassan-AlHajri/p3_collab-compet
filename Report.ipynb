{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bc67575",
   "metadata": {},
   "source": [
    "# Collaboration and Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10df115d",
   "metadata": {},
   "source": [
    "### This notebook reports the method adopted to train an agent for solving the task of Collaboration and Competition for the third project in Udacity's Deep Reinforcement Learning Nanodegree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9a09ee",
   "metadata": {},
   "source": [
    "The learning algorithm I used for this project is a Deep Deterministic Policy Gradient, whose full description can be found in the original paper.\n",
    "\n",
    "DDPG is an actor-critic algorithm, and its basically an extension of DQN to continuous actions spaces.\n",
    "The critic learns to evaluate the optimal action-value functions by using the actor estimated best actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45a3c81",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2deb30",
   "metadata": {},
   "source": [
    "    BUFFER_SIZE = int(1e5)      # replay buffer size\n",
    "    BATCH_SIZE = 256            # minibatch size\n",
    "    GAMMA = 0.99                # discount factor\n",
    "    TAU = 1e-3                  # for soft update of target parameters\n",
    "    LR_ACTOR = 1e-4             # learning rate of the actor \n",
    "    LR_CRITIC = 5e-4            # learning rate of the critic\n",
    "    WEIGHT_DECAY = 0            # L2 weight decay\n",
    "    UPDATE_EVERY = 2            # How often to update the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c92c13",
   "metadata": {},
   "source": [
    "# Plot of Rewards\n",
    "Environment was solved in 1229  episodes\n",
    "\n",
    "![DDPG_Solution_Scores](model_performance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb8ac23",
   "metadata": {},
   "source": [
    "# Future Work\n",
    "* Trying other algorithms like PPO, A3C or D4PG\n",
    "* Trying different NN architect for actor and critic\n",
    "* Change the Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171f520c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
